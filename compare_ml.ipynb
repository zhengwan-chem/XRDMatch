{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def bayes_classifier(train_x, train_y):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "def knn_classifier(train_x, train_y):   \n",
    "    model = KNeighborsClassifier(n_neighbors=2)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "def random_forest_classifier(train_x, train_y):\n",
    "    model = RandomForestClassifier(n_estimators=10)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "def decision_tree_classifier(train_x, train_y):\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "def gradient_boosting_classifier(train_x, train_y):\n",
    "    model = GradientBoostingClassifier(n_estimators=10)\n",
    "#    model = XGBClassifier(n_estimators=10)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "def svm_classifier(train_x, train_y):\n",
    "    model = SVC(kernel='rbf', probability=True)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model\n",
    "\n",
    "def normdata(data):  \n",
    "    min_x = min(data)\n",
    "    max_x = max(data)\n",
    "    norm = max_x - min_x\n",
    "    data = (data - min_x)/norm\n",
    "    return data\n",
    "\n",
    "def data_zero(data):  \n",
    "    num = len(data)\n",
    "    for i in range(num):\n",
    "        if(data[i]<0.1):\n",
    "            data[i]=0\n",
    "    return data\n",
    "\n",
    "def main_eval(data):\n",
    "    dataset = normdata(data)\n",
    "    dataset = data_zero(dataset)    \n",
    "    dataset = np.reshape(dataset,(1,len(dataset)))        \n",
    "    dataset = dataset.astype(np.float32)       \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "classifiers = {'NB':bayes_classifier,   \n",
    "                   'KNN' :knn_classifier,                      \n",
    "                   'RF':random_forest_classifier,  \n",
    "                   'DT':decision_tree_classifier,  \n",
    "                   'SVM':svm_classifier,                    \n",
    "                   'GBDT':gradient_boosting_classifier,          \n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "f = open('c1.txt','w')\n",
    "num = 100\n",
    "f1_p = np.zeros(6)\n",
    "f1 = np.zeros(6)\n",
    "recall_p = np.zeros(6)\n",
    "recall = np.zeros(6)\n",
    "\n",
    "f1 = open('pred_1.csv','w')\n",
    "path_dir = 'lbs_22.csv'\n",
    "with open(path_dir,'r',encoding='utf-8') as fs:\n",
    "    lines = fs.readlines()\n",
    "fs.close()\n",
    "print(lines[0],end='',file=f1)\n",
    "\n",
    "\n",
    "lb_dataset = pd.read_csv('lbs.csv')  \n",
    "img_list = np.array(lb_dataset)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(img_list)\n",
    "lb_data = img_list[:,5:] \n",
    "lb_target = img_list[:,4] \n",
    "lb_name = img_list[:,0]\n",
    "lb_id = img_list[:,1]\n",
    "a = 0\n",
    "c = 0\n",
    "\n",
    "\n",
    "\n",
    "pred_data = []\n",
    "pred_target = []\n",
    "pred_name = []\n",
    "pred_id = []  \n",
    "\n",
    "posi_data = []\n",
    "posi_target = []\n",
    "nega_data = []\n",
    "nega_target = []    \n",
    "posi_name = []\n",
    "posi_id = []  \n",
    "nega_name = []\n",
    "nega_id = []      \n",
    "     \n",
    "for i in range(len(lb_target)):\n",
    "    lb_data[i] = main_eval(lb_data[i])\n",
    "    if(lb_target[i]==0):\n",
    "        a =a+1\n",
    "        if(a<20):\n",
    "            posi_data.append(lb_data[i])\n",
    "            posi_target.append(lb_target[i])\n",
    "            posi_name.append(lb_name[i])\n",
    "            posi_id.append(lb_id[i])            \n",
    "        else:\n",
    "            pred_data.append(lb_data[i])\n",
    "            pred_target.append(lb_target[i])                \n",
    "            pred_name.append(lb_name[i])\n",
    "            pred_id.append(lb_id[i])  \n",
    "for i in range(len(lb_target)):\n",
    "    lb_data[i] = main_eval(lb_data[i])\n",
    "    if(lb_target[i]==1):\n",
    "        c =c+1\n",
    "        if(c<75):\n",
    "            nega_data.append(lb_data[i])\n",
    "            nega_target.append(int(lb_target[i]))\n",
    "            nega_name.append(lb_name[i])\n",
    "            nega_id.append(lb_id[i])                  \n",
    "        else:\n",
    "            pred_data.append(lb_data[i])\n",
    "            pred_target.append(lb_target[i])\n",
    "            pred_name.append(lb_name[i])   \n",
    "            pred_id.append(lb_id[i])              \n",
    "lb_num = 10    \n",
    "\n",
    "for i in posi_id:\n",
    "    print(lines[i+1],end='',file=f1)\n",
    "\n",
    "for i in nega_id:\n",
    "    print(lines[i+1],end='',file=f1)\n",
    "\n",
    "for i in pred_id:\n",
    "    print(lines[i+1],end='',file=f1)\n",
    "f1.close()\n",
    "f2 = open('train_name.txt','w')\n",
    "f3 = open('eval_name.txt','w')\n",
    "for k in range(100):\n",
    "    if k%10==0:\n",
    "        print(k)\n",
    "    np.random.seed(k)            \n",
    "    np.random.shuffle(posi_data)\n",
    "    np.random.shuffle(nega_data)\n",
    "    np.random.shuffle(posi_target)\n",
    "    np.random.shuffle(nega_target)    \n",
    "    np.random.shuffle(posi_name)\n",
    "    np.random.shuffle(nega_name)\n",
    "    \n",
    "    train_x = np.append(posi_data[:lb_num],nega_data[:lb_num]).reshape(lb_num*2,len(lb_data[0]))\n",
    "    train_y = np.append(posi_target[:lb_num],nega_target[:lb_num])\n",
    "    train_y = np.array(train_y)\n",
    "    train_name = np.append(posi_name[:lb_num],nega_name[:lb_num])\n",
    "    \n",
    "    eval_num = len(posi_data) + len(nega_data) - lb_num*2\n",
    "    eval_data = np.append(posi_data[lb_num:],nega_data[lb_num:]).reshape(eval_num,len(lb_data[0]))\n",
    "    eval_target = np.append(posi_target[lb_num:],nega_target[lb_num:])\n",
    "    eval_target = np.array(eval_target)\n",
    "    eval_name = np.append(posi_name[lb_num:],nega_name[lb_num:])\n",
    "    for i in range(len(train_name)):\n",
    "        print(train_name[i],file=f2)\n",
    "    for i in range(len(eval_name)):\n",
    "        print(eval_name[i],file=f3)\n",
    "        \n",
    "    b = 0\n",
    "    for classifier in classifiers: \n",
    "        #predict experimental prediction accuracy\n",
    "        model = classifiers[classifier](train_x, train_y) \n",
    "        predict_lb = model.predict(eval_data)     \n",
    "#        f1[b] = f1_score(eval_target, predict_lb, average='macro')    \n",
    "#        cf_mat = confusion_matrix(predict_lb, eval_target, normalize='true')\n",
    "#        f1_p[b] = f1_p[b] + f1[b]\n",
    "#        recall[b] = (cf_mat[0,0]+cf_mat[1,1])/2\n",
    "#        recall_p[b] = recall_p[b] + recall[b]\n",
    "#        b = b + 1\n",
    "#    print(f1[5])\n",
    "#    print(k,f1[0],f1[1],f1[2],f1[3],f1[4],f1[5],file=f)\n",
    "\n",
    "#print(i,f1_p[0]/100.0,f1_p[1]/100.0,f1_p[2]/100.0\n",
    "#      ,f1_p[3]/100.0,f1_p[4]/100.0,f1_p[5]/100.0,file=f)\n",
    "f2.close()\n",
    "f3.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
